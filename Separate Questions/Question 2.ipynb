{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt  #2\n",
    "\n",
    "#### What words are characteristic of the movie summaries in those genres?\n",
    "\n",
    "For this prompt I will be:\n",
    "-  First associating each word with a part-of-speech (POS) tag while still in its original context\n",
    "-  Using POS tags to lemmatize words\n",
    "-  Compute Term Frequency - Inverse Document Frequency scores for the lemmatized corpus\n",
    "-  Parse POS distribution for each genre\n",
    "-  Display and interpret top TF-IDF scores\n",
    "-  Explore Latent Dirichlet Allocation (LDA) to determine genres' \"topics\"\n",
    "\n",
    "We start by importing necessary modules and the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>box_office_revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>genres</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>14010832.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>[Space western, Horror, Supernatural, Thriller...</td>\n",
       "      <td>Set in the second half of the 22nd century, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>White Of The Eye</td>\n",
       "      <td>1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>[Erotic thriller, Psychological thriller, Thri...</td>\n",
       "      <td>A series of murders of rich young women throug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A Woman in Flames</td>\n",
       "      <td>1983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.0</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>Eva, an upper class housewife, becomes frustra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The Sorcerer's Apprentice</td>\n",
       "      <td>2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>[Adventure, Fantasy, World cinema, Family Film]</td>\n",
       "      <td>Every hundred years, the evil Morgana  returns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Little city</td>\n",
       "      <td>1997-04-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>[Romance Film, Ensemble Film, Comedy-drama, Co...</td>\n",
       "      <td>Adam, a San Francisco-based artist who works a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                      title release_date  box_office_revenue  runtime  \\\n",
       "0   0             Ghosts of Mars   2001-08-24          14010832.0     98.0   \n",
       "1   1           White Of The Eye         1987                 NaN    110.0   \n",
       "2   2          A Woman in Flames         1983                 NaN    106.0   \n",
       "3   3  The Sorcerer's Apprentice         2002                 NaN     86.0   \n",
       "4   4                Little city   1997-04-04                 NaN     93.0   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [Space western, Horror, Supernatural, Thriller...   \n",
       "1  [Erotic thriller, Psychological thriller, Thri...   \n",
       "2                                            [Drama]   \n",
       "3    [Adventure, Fantasy, World cinema, Family Film]   \n",
       "4  [Romance Film, Ensemble Film, Comedy-drama, Co...   \n",
       "\n",
       "                                             summary  \n",
       "0  Set in the second half of the 22nd century, th...  \n",
       "1  A series of murders of rich young women throug...  \n",
       "2  Eva, an upper class housewife, becomes frustra...  \n",
       "3  Every hundred years, the evil Morgana  returns...  \n",
       "4  Adam, a San Francisco-based artist who works a...  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import ast\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from stop_words import get_stop_words\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "\n",
    "movies = pd.read_csv(\"movie_data.csv\")\n",
    "\n",
    "movies['genres'] = pd.Series(ast.literal_eval(genres) for genres in movies['genres'])\n",
    "\n",
    "movies.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we want to group summaries of the same genre together. Note there is no reasonable way for us to create disjoint groups, hence we allow a movie to belong to more than one genre grouping. \n",
    "\n",
    "In this process we also want to take the opportunity to add part-of-speech(POS) tags to each word. We can only determine an individual word's speech tag (e.g. Verb, Adjective, etc) when we observe it in context. As linguist J.R. Firth said, \"You shall know a word by the company it keeps.\" The POS tags will allow us to lemmatize the words (Further explained below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_genres = [\"Drama\", \"Comedy\", \"Action/Adventure\", \"Romance Film\", \"Thriller\"]\n",
    "\n",
    "genres_list = {genre: [] for genre in unique_genres}\n",
    "\n",
    "for genre in unique_genres:\n",
    "    for genres, summary in zip(movies['genres'], movies['summary']):\n",
    "        \n",
    "        if genre in genres:\n",
    "            \n",
    "            genres_list[genre].append(nltk.pos_tag(summary.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions help with the necessary translations required when using the NLTK's lemmatizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get_wordnet_pos maps tags from NLTK's pos_tag to tags utilized in the lemmatizing method.\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "#Used to associate lemmatized tag object to literal string name\n",
    "def tag_helper(word,tag):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    wntag = get_wordnet_pos(tag)\n",
    "    \n",
    "    #Not supply tag in case of None\n",
    "    if wntag is None:\n",
    "        lemma = wnl.lemmatize(word)\n",
    "        tb_tag = \"\"\n",
    "        \n",
    "    #Assigning a variable to the english equivalent of our tags\n",
    "    else:\n",
    "        lemma = wnl.lemmatize(word, pos = wntag)\n",
    "        if wntag == wordnet.ADJ:\n",
    "            tb_tag = \"Adjective\"\n",
    "        elif wntag == wordnet.VERB:\n",
    "            tb_tag = \"Verb\"\n",
    "        elif wntag == wordnet.NOUN:\n",
    "            tb_tag = \"Noun\"\n",
    "        elif wntag == wordnet.ADV:\n",
    "            tb_tag = \"Adverb\"\n",
    "        elif wntag is None:\n",
    "            tb_tag = \"\"\n",
    "            \n",
    "    return lemma, tb_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use lemmatization to bring words up a level in abstraction and away from their more specific use. By lemmatizing a corpus of words we reduce the morphological variation. For instance, \"better\" becomes \"good\", \"running\" and \"ran\" become \"run\", \"frustrated\" maps to \"frustrate\", and so on. By aggregating words into their base form we can come to more accurate characterizations through the term-frequency inverse document-frequency (TF-IDF) score. \n",
    "\n",
    "Further, since parts-of-speech are necessary for lemmatization we are able to characterize genres' words by POS distribution. (e.g. Is the proportion of verbs used in Action/Adventure different than Comedy?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2743970"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Genre name is key with list of lemmed summaries (in list form)\n",
    "lem_dict = {} \n",
    "\n",
    "#Same structure as lem_dict but with POS\n",
    "tag_dict ={} \n",
    "\n",
    "#We count the number of times we successfully map a word to its lemmatized form just to satisfy curiosity\n",
    "lem_count = 0\n",
    "for genre,tup_list in genres_list.items():\n",
    "    \n",
    "    #list that contains all lemmed summaries for a given genre\n",
    "    temp_lem = [] \n",
    "    temp_pos = []\n",
    "    for summary in tup_list:\n",
    "            \n",
    "        #list of lemmed words for a given summary\n",
    "        summary_lem = [] \n",
    "        summary_pos = []\n",
    "\n",
    "        for tup in summary:\n",
    "\n",
    "            _word, _tag = tup\n",
    "            #Leave out proper nouns (NNP), plural proper nouns (NNPS), and personal pronouns (PRP)\n",
    "            if str(_tag) != \"NNP\" or str(_tag) != \"NNPS\" or str(_tag) != \"PRP\" or str(_tag) != \"PRP$\":\n",
    "                #We let compound words stay as is (e.g. chimney-sweep)\n",
    "                _word = _word.lower().replace(\".\", \"\").strip('\"!,')\n",
    "\n",
    "                #Performs lemmatization and converts POS tag into full form (e.g. \"Adjective\", \"Noun\", etc)\n",
    "                lemma, tag = tag_helper(_word, _tag) \n",
    "\n",
    "                #Counter to see how many words we changed\n",
    "                if lemma != _word:\n",
    "                    lem_count += 1\n",
    "                    \n",
    "                if lemma != \"\":    \n",
    "                    summary_lem.append(lemma)\n",
    "                    summary_pos.append(tag)\n",
    "\n",
    "        temp_lem.append(summary_lem)\n",
    "        temp_pos.append(summary_pos)\n",
    "\n",
    "    lem_dict[genre] = temp_lem\n",
    "    tag_dict[genre] = temp_pos\n",
    "print(\"Number of words converted to their lemmatized form:\", len(lem_count))     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute the TF-IDF score for the lemmas. We start by computing term frequency of each lemma across all summaries and follow up by counting how many summaries (\"documents\") each lemma appears in. We use raw term count rather than actual term frequency as we are only concered with ranking and so they are proportionally equivalent.\n",
    "\n",
    "__Note__: In the previous code block we threw out all proper nouns, singular and plural, and also all personal pronouns. Since movie characters' names can be used numerous times in an individual movie's summary but not in any other movie's summary it necessarily has a high TF-IDF score. Without discarding proper nouns much of the top n highest TF-IDF scores belonged to words that did not help us characterize genres whatsoever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words in corpus: 177612\n"
     ]
    }
   ],
   "source": [
    "#Building vocab set now helps us simply do dict comprehensions and slightly simplifies tf and df dict creation\n",
    "vocab = set()\n",
    "for genre, summaries in lem_dict.items():\n",
    "    for summary in summaries:\n",
    "        for word in summary:\n",
    "            vocab.add(word)\n",
    "            \n",
    "vocab = list(vocab)\n",
    "\n",
    "\n",
    "tf = {genre: {word: 0 for word in vocab} for genre in unique_genres}\n",
    "df = {genre: {word: 0 for word in vocab} for genre in unique_genres}\n",
    "\n",
    "for genre, summaries in lem_dict.items():\n",
    "    for summary in summaries:\n",
    "        \n",
    "        #We create a temp docuement frequency list to ensure that even if a word shows up multiple times in...\n",
    "        #...a document it is only counted in df once\n",
    "        temp_df = []\n",
    "        \n",
    "        for word in summary:\n",
    "            tf[genre][word] += 1\n",
    "            \n",
    "            #Had we not used temp_df here we would just be counting like tf\n",
    "            if word not in temp_df:\n",
    "                df[genre][word] += 1\n",
    "                temp_df.append(word)\n",
    "                \n",
    "tf_idf = {genre: {word: 0 for word in vocab} for genre in unique_genres}\n",
    "\n",
    "for genre in unique_genres:\n",
    "    for word in vocab:\n",
    "        \n",
    "        #We use 1 + the number of documents a word has appeared to avoid division by 0 in the idf term\n",
    "        tf_idf[genre][word] = tf[genre][word] * np.log(len(lem_dict[genre]) / (1 + df[genre][word]))\n",
    "        \n",
    "print(\"Total unique words in corpus:\",len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before dissecting TF-IDF scores let's consider what the part-of-speech make-up is for the genres. When looking at the distribution of parts-of-speech across genres it's best to look at intra-distributions proportionally considering there is large variation in number of summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Romance Film:\n",
      "Verb :  31.05%\n",
      "Adjective :  10.15%\n",
      "Adverb :  6.55%\n",
      "Noun :  52.26%\n",
      "...\n",
      "...\n",
      "Thriller:\n",
      "Verb :  31.23%\n",
      "Adjective :  9.52%\n",
      "Adverb :  5.92%\n",
      "Noun :  53.32%\n",
      "...\n",
      "...\n",
      "Comedy:\n",
      "Verb :  30.32%\n",
      "Adjective :  10.01%\n",
      "Adverb :  6.5%\n",
      "Noun :  53.18%\n",
      "...\n",
      "...\n",
      "Drama:\n",
      "Verb :  30.47%\n",
      "Adjective :  10.42%\n",
      "Adverb :  6.19%\n",
      "Noun :  52.93%\n",
      "...\n",
      "...\n",
      "Action/Adventure:\n",
      "Adjective :  9.39%\n",
      "Verb :  30.3%\n",
      "Adverb :  5.67%\n",
      "Noun :  54.64%\n",
      "...\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "pos_counts = {genre: {} for genre in unique_genres}\n",
    "\n",
    "#Building out the totals for each part-of-speech for each genre\n",
    "for genre in unique_genres:\n",
    "    for tags in tag_dict[genre]:\n",
    "        for tag in tags:\n",
    "            if tag != \"\":\n",
    "                pos_counts[genre][tag] = pos_counts[genre].get(tag, 0) + 1\n",
    "\n",
    "#Here we normalize the totals so we can compare proportions across genres\n",
    "for genre, pos_dict in pos_counts.items():\n",
    "    temp_total = 0\n",
    "    \n",
    "    #Summing pos counts\n",
    "    for parts in pos_dict.values():\n",
    "        temp_total += parts\n",
    "    \n",
    "    #Normalizing\n",
    "    for types in pos_dict.keys():\n",
    "        pos_counts[genre][types] = pos_counts[genre][types] / temp_total\n",
    "    \n",
    "for genre, types in pos_counts.items():\n",
    "    print(\"{}:\".format(genre))\n",
    "    \n",
    "    for pos, res in types.items():\n",
    "        print(pos, \": \", \"{}%\".format(round(100*res,2)))\n",
    "        \n",
    "    print(\"...\")\n",
    "    print(\"...\")       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps not so surprisingly there are no significant differences across genres in types of speech used. We therefore must rely and look to the words themselves to differentiate and characterize genres.\n",
    "***\n",
    "Now back to the TF-IDF scores. Let's look at the highest scoring 30 words from each genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_words = {genre: None for genre in unique_genres}\n",
    "\n",
    "for genre in unique_genres:\n",
    "    temp_top = sorted(tf_idf[genre], key=tf_idf[genre].get, reverse=True)[:100]\n",
    "    temp_top = [word for word in temp_top if word != \"\"]\n",
    "    top_words[genre] = temp_top\n",
    "\n",
    "#This forces jupyter to display all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "top_100 = pd.DataFrame.from_dict(top_words)\n",
    "top_100;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the dataframe below we can see some interesting results. To save the reader from some scrolling here are noteworthy words that seem to characterize the genres in line with our intuition.\n",
    "\n",
    "Note the listings are given in descending order according to TF-IDF rank.\n",
    "***\n",
    " - __Action/Adventure__: - Kill, - Police, - Gang, - Fight, - Shoot, - Escape, - Attack, - Money, - Agent, - Gun, - Order, - Force, - Ship, - Officer, - Death, and even a very specific Action/Adeventure hero - Bond.\n",
    "<br><br> \n",
    " - __Comedy__: - Leave, - Kill, - Family, - Friend, - House, - Love, - School, - Money, - Mother, - Work, - Help, - Bug\n",
    "<br><br>\n",
    " - __Drama__: - Kill, - Father, - Leave, - Love, - Family, - Mother, - Home, - House, - Return, - Friend, - Son, - Life, - Police, - Child, - Work, - Wife, - Money, - School, - Daughter\n",
    "<br><br>\n",
    " - __Romance Film__: - Father, - Leave, - Love, - Family, - Mother, - Return, - Friend, - Marry, - Home, - House, - Kill, - Life, - Time, - Relationship, - Son, - Help\n",
    "<br><br>\n",
    " - __Thriller__: - Kill, - Police, - House, - Car, - Leave, - Escape, - Shoot, - Father, - Murder, - Money, - Attack, - Return, - Home, - Meet, -Body, - Reveal, - Time, - Death, - Run, - Family, - Gun, - Mother"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Action/Adventure and Thriller both seem to be characterized well as genres by their high-scoring TF-IDF words. It would come as no surprise for a Action/Adventure summary to mention police, gangs, fights, killings, shots, escapes, attacks, agents, and etc. These words actually seem to do a relatively good job describing some of the genres in toto.\n",
    "\n",
    "Though it is obvious some genres highlighted words seem to match their respective genre better than others. Comedy for instance doesn't really have any truly defining characteristic words for their summaries. Which makes some sense seeing as how comedies plots are less constrained than say a Thriller's is. I would be hard-pressed to come up with defining general characteristics of a comedy's summary.\n",
    "\n",
    "As seen in the list $alike$ below, every genre actually shares 65 of their 100 characterizing words. Most of these words are easy to understand being used frequently in descriptions of any stories. Yet some of them convey information about what summaries overall, and hence the movies themselves, are about. Generally these genres contain themes about friendship, killing, new meetings, returning to what once was, and families. Or at least that's what these characterizing words, along with a vague understanding of movie narratives, point to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'but', 'they', 'when', 'on', 'will', 'friend', 'do', 'begin', 'it', 'her', 'film', 'off', 'kill', 'time', 'he', 'call', 'while', 'after', 'then', 'all', 'try', 'come', 'him', 'an', 'from', 'new', 'return', 'out', 'be', 'for', 'one', 'meet', 'father', 'who', 'have', 'find', 'two', 'about', 'with', 'not', 'family', 'get', 'by', 'this', 'that', 'she', 'help', 'his', 'up', 'their', 'leave', 'see', 'go', 'at', 'make', 'back', 'them', 'before', 'take', 'tell', 'which', 'where', 'give', 'man', 'into'}\n"
     ]
    }
   ],
   "source": [
    "alike = set(top_100[unique_genres[0]])\n",
    "\n",
    "for i in range(len(unique_genres)):\n",
    "    if i != len(unique_genres) - 1:\n",
    "        alike = alike.intersection(set(top_100[unique_genres[i + 1]]))\n",
    "        \n",
    "print(alike)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's explore the genres using Latent Dirichlet Allocation (LDA). LDA assumes documents are produced from a mixture of topics. Those topics then generate words based on their probability distribution. So since LDA assumes that a document is created with certain topic proportion rules, its goal is to backtrack and determine which topics would lead to the given documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "en_stop = get_stop_words('en')\n",
    "\n",
    "#For LDA we take the lemmed summaries from above and simply remove stop-words\n",
    "lda_dict = {}\n",
    "for genre, summaries in lem_dict.items():\n",
    "    temp_summaries = []\n",
    "    for summary in summaries:\n",
    "        temp_summary = []\n",
    "        for word in summary:\n",
    "            if word not in en_stop and word != \"\":\n",
    "                temp_summary.append(word)\n",
    "                \n",
    "        temp_summaries.append(temp_summary)\n",
    "        \n",
    "    lda_dict[genre] = temp_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_dict = {}\n",
    "corpus_dict = {}\n",
    "ldamodels = []\n",
    "\n",
    "for genre in unique_genres:\n",
    "    \n",
    "    #Dictionary traverses summaries assigning a unique id to each token while collecting word counts\n",
    "    dict_dict[genre] = corpora.Dictionary(lda_dict[genre])\n",
    "    \n",
    "    #Here we create a bag-of-words model from our Dictionary structures just created\n",
    "    corpus_dict[genre] = [dict_dict[genre].doc2bow(text) for text in lda_dict[genre]]\n",
    "    \n",
    "    #Our corpus_dict contains Document-term matrices for each genre. We now find the LDA models\n",
    "    ldamodels.append(gensim.models.ldamodel.LdaModel(corpus_dict[genre], num_topics = 3, \n",
    "                                                         id2word = dict_dict[genre], passes = 20))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following results show us possible topic distribution models used to create the summaries found in our data. Though largely ambiguous, the models are slightly telling and somewhat relate to our intuitive understanding of these genres.\n",
    "\n",
    "For example in Action/Adventure we see \"kill\", \"take\", \"one\" and \"find\" show up, which makes sense for a vague description for many movies that fall under this genre. A character must \"find\" some treasure, \"take\" back some secret plans from the enemy, or \"kill\" the villain to save the day. \"Kill\", \"police\", \"find\", and \"take\" seems reasonable for a Thriller by this same logic. Also note under Romance Film each of the topics contains \"love\", which we should definitely expect for such a genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drama\n",
      "[(0, '0.009*\"get\" + 0.007*\"love\" + 0.006*\"go\" + 0.006*\"take\"'), (1, '0.005*\"go\" + 0.005*\"tell\" + 0.005*\"find\" + 0.005*\"leave\"'), (2, '0.007*\"kill\" + 0.005*\"take\" + 0.004*\"find\" + 0.004*\"one\"')]\n",
      "...\n",
      "...\n",
      "Comedy\n",
      "[(0, '0.007*\"get\" + 0.006*\"love\" + 0.005*\"go\" + 0.005*\"take\"'), (1, '0.004*\"get\" + 0.004*\"find\" + 0.004*\"take\" + 0.004*\"go\"'), (2, '0.007*\"get\" + 0.006*\"go\" + 0.006*\"find\" + 0.005*\"take\"')]\n",
      "...\n",
      "...\n",
      "Action/Adventure\n",
      "[(0, '0.007*\"kill\" + 0.005*\"take\" + 0.004*\"find\" + 0.004*\"one\"'), (1, '0.006*\"kill\" + 0.006*\"take\" + 0.005*\"find\" + 0.004*\"go\"'), (2, '0.007*\"kill\" + 0.005*\"take\" + 0.005*\"get\" + 0.005*\"find\"')]\n",
      "...\n",
      "...\n",
      "Romance Film\n",
      "[(0, '0.007*\"go\" + 0.007*\"get\" + 0.006*\"tell\" + 0.006*\"love\"'), (1, '0.004*\"take\" + 0.004*\"love\" + 0.004*\"find\" + 0.004*\"return\"'), (2, '0.011*\"love\" + 0.007*\"get\" + 0.005*\"take\" + 0.005*\"father\"')]\n",
      "...\n",
      "...\n",
      "Thriller\n",
      "[(0, '0.008*\"find\" + 0.006*\"kill\" + 0.006*\"go\" + 0.006*\"tell\"'), (1, '0.008*\"kill\" + 0.005*\"police\" + 0.005*\"take\" + 0.005*\"find\"'), (2, '0.008*\"kill\" + 0.005*\"take\" + 0.004*\"one\" + 0.004*\"find\"')]\n",
      "...\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ldamodels)):\n",
    "    print(unique_genres[i])\n",
    "    print(ldamodels[i].print_topics(num_topics = 3, num_words = 4))\n",
    "    print(\"...\")\n",
    "    print(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
